1. Gesture Recognition is a field of AI that relies almost completely on computer vision. The base of the gesture recognition is being able to visually see (either with a camera in the visible light spectrum or some other sensor) what motion is being done, understanding what that motion is, and then doing some sort of action based off of that motion. Collecting the data for very simple gesture recognition relies on 2-D tracking and motion trajectories. These are not always completely sufficient, however, and some applications required 3-D tracking. One technique used for static hand posture recognition is Elastic Graph Matching, which involves representing the hand as a labelled graph with a two-dimensional topology, but this does require the hand to have a specific orientation, it is not view-independent. Another method is Local Linear Mapping, which consists of detecting the 2-D location of fingertips, and then mapping those to a 3-D position. This can recognize the same gestures from different views. Recognizing dynamic hand gestures is much more difficult. One method of doing this is to use a finite state machine, that can recognize specific static hand gestures and then follow a sequence of them to recognize one dynamic gesture. Another method is rule-based modelling with an induction algorithm that learns to recognize 3-D gestures based off an initial set of gesture recognition rules. Bayesian Networks have also been used for this. A final method of gesture recognition is the HMM model. It is a type of statistical model, which involves states and the probability of transitioning between them.  These models can take into account not only the perceived gesture, but what the probability is that the perceived gesture is a gesture that makes sense in that situation. Based off of this information, the model can determine what it thinks is the most probable state. There have been many suggestions for how to improve the HMM model beyond the standard, often involving more dynamic gestures and very complicated state transitions.

Wu, Ying, and Thomas S. Huang. "Vision-based gesture recognition: A review." Gesture-based communication in human-computer interaction. Springer Berlin Heidelberg, 1999. 103-115.

2. The definition of Artificial Intelligence does not include being able to solve 100% of all problems that exist. The fact that certain types of problems are intractable or undecidable for computers at the present moment in time does not mean that they will be that way forever, nor does it mean that AI is impossible. We often base our concept of intelligence off of "human intelligence" and there are many problems that humans are unable to solve. This does not mean that humans are not intelligent. Furthermore, there are many problems that were, for years, thought to be unsolvable, but were later revealed to have solutions. We cannot predict the exact evolution of technology, in both hardware and software, and thus there is no basis for describing AI as impossible because it currently fails to solve certain problems.

3. This statement is false. The first thing that is incorrect about this statement is the entire notion that computers can only do what their programmers tell them to. While this is true to a degree, it entirely reduces the concept of machine learning and awareness to nothingness. No programmer ever told Siri that when someone asks it what hours the Statue of Liberty is open the answer is 10am - 6pm. Likewise, no programmer ever told Stanley that if it reaches a specific GPS coordinate it must be careful of the cliff on its left. In both cases there is an element of understanding that the AI must have. Siri must be able to understand the question that is being asked of it, and Stanley must be able to understand what obstacles and dangers are around it. While it is true that a programmer gave Siri and Stanley the ability to understand these things, they never told them specifically how to respond. The actual actions of the machine are determined by itself, based on broad guidelines and specific goals. Deep Blue was not told what moves to make in certain situations, it was just told to win a chess game. It is possible to abstract this up a level, and interpret the question as stating that "Computers cannot be intelligent because they do not have free will." This is also not a legitimate argument. Intelligence and lack of free will are not mutually exclusive. Just because a computer's goal is defined by a programmer does not mean that its not intelligent. One great example of this is chess playing robots. With the advent of chess playing AIs that had learning functions, many quickly became better than their programmers, even though they were initially worse. Even though the programmer instructed the AI to win the chess game, it displayed intelligence through learning and eventually besting the programmer.

4. Performance measure, Environment, Actuators, Sensors
	i. Ping-pong playing agent
		P: Maximize the probability of hitting the ping-pong ball before it bounces twice so that it lands on the table on the opposite side of the net while minimizing the probability that the opposing player will be able to hit it. Ultimate goal is to score a certain number of points before the opposing player
		E: The ping-pong table, including the table surface, the net, and the ball.
		A: Motion and control of the ping-pong paddle
		S: Must be able to track the location of the ping-pong ball, the location of the opposing player, the agent's own ping-pong paddle and the location of the table and net. Sensors most likely include cameras, accelerometers, and gyroscopes.
	ii. Mathematician's Theorem-Proving Assistant
		P: Minimize number of steps to find the solution to a given theorem
		E: The theorem provided by the mathematician, and the definition of all mathematical constructs necessary for finding a solution
		A: No physical actuators, but should have a set of pre-defined mathematical manipulations that it can perform.
		S: Must be able to read/interpret the given theorem, the constructs it is aware of, the manipulations it is capable of, and be able to determine when it has reached the solution/goal state.

5. 